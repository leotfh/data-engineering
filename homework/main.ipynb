{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd355fb7",
   "metadata": {},
   "source": [
    "# Homework - Paul Bichl & Leo Traußnigg\n",
    "## Data from Smart Home - PV power, UV radiation and Boiler Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a324c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_sensor_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c63665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dat from csv file\n",
    "def plot_sensor_data(data):\n",
    "    if data['state'] is not None:\n",
    "        data['state'].plot()\n",
    "        plt.title('Sensor Data')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(data['entity_id'][0])\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae847af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_duplicates(data, duplicates):\n",
    "    if duplicates > 0:\n",
    "        for _ in range(duplicates):\n",
    "            data = pd.concat([data, data.iloc[0:1]], ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428a4cf-b5dc-47ab-b48b-e57f8ccca56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "\n",
    "    try: \n",
    "        # convert weird date format to actual datetime\n",
    "        data['last_changed'] = pd.to_datetime(data['last_changed'])\n",
    "        \n",
    "        # Define cutoff timestamp\n",
    "        cutoff = pd.Timestamp('2025-03-21T12:00:00.000Z')\n",
    "        \n",
    "        # Filter the data: keep rows where last_changed >= cutoff\n",
    "        data = data[data[\"last_changed\"] >= cutoff].reset_index(drop=True)\n",
    "\n",
    "        # check for duplicate entries\n",
    "        if data.duplicated(subset=['last_changed']).any():\n",
    "            print(\"Duplicate entries found. Removing duplicates.\")\n",
    "            data = data.drop_duplicates(subset=['last_changed']).reset_index(drop=True)\n",
    "        \n",
    "        # Remove rows where 'state' is 'unknown' or 'unavailable'\n",
    "        data = data[~data[\"state\"].isin([\"unknown\", \"unavailable\", \"NaN\", \"nan\"])].reset_index(drop=True)\n",
    "\n",
    "        # Convert string 'state' to number\n",
    "        data['state'] = data['state'].astype('float')\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215b3ad-2987-443b-816f-031d230e3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiation_data = read_sensor_data('data/radiation-history.csv')\n",
    "pv_data = read_sensor_data('data/pv-power-history.csv')\n",
    "solar_lux_data = read_sensor_data('data/solar_lux.csv')\n",
    "\n",
    "insert_duplicates(radiation_data, 2)\n",
    "\n",
    "radiation_data = clean_data(radiation_data)\n",
    "pv_data = clean_data(pv_data)\n",
    "solar_lux_data = clean_data(solar_lux_data)\n",
    "\n",
    "# plot_sensor_data(radiation_data)\n",
    "# plot_sensor_data(pv_data)\n",
    "# plot_sensor_data(solar_lux_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00878d-7d1a-486b-91e2-d8105c6ed334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'last_changed' and clean up the columns\n",
    "\n",
    "merged_data = pv_data.merge(radiation_data, on='last_changed', suffixes=('_pv', '_rad')).merge(solar_lux_data, on='last_changed', suffixes=('', '_lux'))\n",
    "merged_data = merged_data.rename(columns={'state': 'state_lux'})\n",
    "merged_data = merged_data.drop(columns=[col for col in merged_data.columns if col.startswith('entity_id')])\n",
    "\n",
    "print(merged_data)\n",
    "\n",
    "plt.semilogy(merged_data['state_rad'][:100], linewidth='2')\n",
    "plt.semilogy(merged_data['state_lux'][:100], linewidth='0.5', linestyle='--')\n",
    "plt.semilogy(merged_data['state_pv'][:100], linewidth='1')\n",
    "\n",
    "plt.title('Sensor Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sensor Values (log scale)')\n",
    "plt.legend([r'Radiation $\\left(\\frac{W}{m^2}\\right)$', 'Light Emission (lux)', 'PV Power (W)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb8772-f478-4626-9e41-848173e5c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = merged_data.isnull().sum()\n",
    "missing_values += merged_data.isna().sum()\n",
    "print(\"Missing values in merged data:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2703ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report\n",
    "\n",
    "# Encode the 'state_pv' column as a categorical variable\n",
    "le = LabelEncoder()\n",
    "merged_data['solar_encoded'] = le.fit_transform(merged_data['state_pv'])\n",
    "print(merged_data['solar_encoded'])\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(merged_data[['state_rad', 'state_lux']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, merged_data['solar_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf = RidgeCV(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5526100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "Y_pred = rf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "\n",
    "# mse = mean_squared_error(Y_test, Y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(Y_test, Y_pred)\n",
    "# r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "# print(f\"MAE: {mae:.2f}\") # (Lower is better)\n",
    "# print(f\"MSE: {mse:.2f}\") # (Lower is better)\n",
    "# print(f\"RMSE: {rmse:.2f}\") # (Lower is better)\n",
    "# print(f\"R²: {r2:.2f}\") # (1 is perfect, 0 is no correlation)\n",
    "\n",
    "plt.plot(Y_test.values[:100], label='True Values', alpha=0.4, linewidth=3)\n",
    "plt.plot(Y_pred[:100], label='Predicted Values', alpha=1, linestyle='--', linewidth=1)\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Encoded Solar State')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load the model\n",
    "import joblib\n",
    "joblib.dump(rf, 'solar_model.pkl')\n",
    "rf_loaded = joblib.load('solar_model.pkl')\n",
    "\n",
    "# Predict using the loaded model\n",
    "Y_pred_loaded = rf_loaded.predict(X_test)\n",
    "print(\"Predictions from loaded model:\")\n",
    "# print(Y_pred_loaded)\n",
    "print(classification_report(Y_test, Y_pred_loaded))\n",
    "for pred, true in zip(Y_pred_loaded, Y_test):\n",
    "    print(f\"Predicted: {pred}, Actual: {true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da6dab",
   "metadata": {},
   "source": [
    "Save to SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ba01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://user:passwd@localhost/smart_home\")\n",
    "\n",
    "# Save merged_data to MySQL table \"processed_sensor_data\"\n",
    "merged_data.to_sql('processed_sensor_data', engine, if_exists='replace', index=False, method='multi')\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658b1fd",
   "metadata": {},
   "source": [
    "Create SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303dd22",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "queries = []\n",
    "\n",
    "# 1. Select all rows where PV power is greater than 10kW\n",
    "queries.append(\"SELECT * FROM processed_sensor_data WHERE state_pv > 10000\")\n",
    "\n",
    "# 2. Find the day with the highest average PV power (whole day average)\n",
    "queries.append(r\"\"\"\n",
    "SELECT day, avg_pv_power FROM (\n",
    "    SELECT DATE(last_changed) AS day, AVG(state_pv) AS avg_pv_power\n",
    "    FROM processed_sensor_data\n",
    "    GROUP BY day\n",
    ") AS daily_avg\n",
    "ORDER BY avg_pv_power DESC\n",
    "LIMIT 1\n",
    "\"\"\")\n",
    "\n",
    "# 3. Find the average radiation and PV power for each day\n",
    "queries.append(\"\"\"\n",
    "SELECT DATE(last_changed) as day, AVG(state_rad) as avg_radiation, AVG(state_pv) as avg_pv_power\n",
    "FROM processed_sensor_data\n",
    "GROUP BY day\n",
    "ORDER BY day\n",
    "\"\"\")\n",
    "\n",
    "# 4. Get the maximum PV power recorded and the corresponding timestamp\n",
    "queries.append(\"\"\"\n",
    "SELECT last_changed, state_pv\n",
    "FROM processed_sensor_data\n",
    "WHERE state_pv = (SELECT MAX(state_pv) FROM processed_sensor_data)\n",
    "\"\"\")\n",
    "\n",
    "# 5. Select all rows where radiation is below 500 and PV power is above 500\n",
    "queries.append(\"SELECT * FROM processed_sensor_data WHERE state_rad < 50 AND state_pv > 500\")\n",
    "\n",
    "# Example: execute and print the queries using the SQLAlchemy engine\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"Query {i}:\\n{query}\\n\")\n",
    "    result = pd.read_sql_query(query, engine)\n",
    "    print(result.head())\n",
    "    print(\"\\n\" + \"_________________________________________\" + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
